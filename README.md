
# ğŸš— Vehicle Insurance Prediction using MLOps

This project demonstrates a **complete end-to-end MLOps pipeline** â€” from **data ingestion to deployment** â€” using modern DevOps and ML lifecycle practices.
It showcases how to build a **production-ready ML system** integrating **MongoDB, AWS (S3, ECR, EC2), Docker, and CI/CD with GitHub Actions**.

---

## ğŸ“‹ Table of Contents

* [ğŸ¯ Project Overview](#-project-overview)
* [ğŸ§© Tech Stack](#-tech-stack)
* [ğŸ—ï¸ Project Architecture](#ï¸-project-architecture)
* [âš™ï¸ Step-by-Step Implementation](#ï¸-step-by-step-implementation)

  * [1ï¸âƒ£ Project Setup](#1ï¸âƒ£-project-setup)
  * [2ï¸âƒ£ MongoDB Setup](#2ï¸âƒ£-mongodb-setup)
  * [3ï¸âƒ£ Logging, Exception & EDA](#3ï¸âƒ£-logging-exception--eda)
  * [4ï¸âƒ£ Data Ingestion](#4ï¸âƒ£-data-ingestion)
  * [5ï¸âƒ£ Data Validation, Transformation & Model Training](#5ï¸âƒ£-data-validation-transformation--model-training)
  * [6ï¸âƒ£ AWS & Model Deployment Setup](#6ï¸âƒ£-aws--model-deployment-setup)
  * [7ï¸âƒ£ CI/CD Pipeline Setup](#7ï¸âƒ£-cicd-pipeline-setup)
* [ğŸ§  Features](#-features)
* [ğŸš€ Deployment](#-deployment)
* [ğŸ–¥ï¸ App Access](#ï¸-app-access)
* [ğŸ“¦ Folder Structure](#-folder-structure)
* [ğŸ“š References](#-references)

---

## ğŸ¯ Project Overview

This MLOps project demonstrates:

* Building a **machine learning pipeline** for vehicle data prediction.
* Automating each stage of the ML lifecycle â€” data ingestion, validation, transformation, model training, evaluation, and deployment.
* Integrating **CI/CD pipelines** to automate builds, testing, and deployment on **AWS EC2**.
* Deploying the trained ML model inside a **Docker container** for scalable serving.

---

## ğŸ§© Tech Stack

| Category            | Tools / Technologies        |
| ------------------- | --------------------------- |
| Language            | Python 3.10                 |
| Database            | MongoDB Atlas               |
| Cloud Services      | AWS S3, EC2, ECR, IAM       |
| Containerization    | Docker                      |
| CI/CD               | GitHub Actions              |
| Version Control     | Git & GitHub                |
| ML Framework        | Scikit-learn, Pandas, NumPy |
| Web Framework       | Fast API                    |
| Virtual Environment | Conda                       |

---

## ğŸ—ï¸ Project Architecture

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        Data Source (CSV)     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    MongoDB Atlas (Cloud DB)
                               â”‚
                               â–¼
                      Data Ingestion Layer
                               â”‚
                               â–¼
                    Data Validation & Transformation
                               â”‚
                               â–¼
                         Model Training
                               â”‚
                               â–¼
                         Model Evaluation
                               â”‚
                               â–¼
                        Model Registry (AWS S3)
                               â”‚
                               â–¼
                      Model Deployment (EC2)
                               â”‚
                               â–¼
                      Web App (Fast + HTML)
```

---

## âš™ï¸ Step-by-Step Implementation

### 1ï¸âƒ£ Project Setup

* Create a project template by executing `template.py`.
* Configure `setup.py` and `pyproject.toml` for local package imports.
* Create and activate a virtual environment:

  ```bash
  conda create -n vehicle python=3.10 -y
  conda activate vehicle
  pip install -r requirements.txt
  ```
* Verify installation:

  ```bash
  pip list
  ```

---

### 2ï¸âƒ£ MongoDB Setup

1. Create a **MongoDB Atlas** account and new project.
2. Deploy a **free cluster (M0)** and create a database user.
3. Add IP access (`0.0.0.0/0`) for global access.
4. Get your **connection string**:

   ```
   mongodb+srv://<username>:<password>@cluster.mongodb.net/
   ```
5. Load your dataset via Jupyter Notebook (`mongoDB_demo.ipynb`).
6. Verify uploaded data in MongoDB Collections.

---

### 3ï¸âƒ£ Logging, Exception & EDA

* Implement `logger.py` and `exception.py` for debugging and monitoring.
* Perform **EDA and feature engineering** on the dataset in a dedicated notebook.

---

### 4ï¸âƒ£ Data Ingestion

* Create configuration and entity classes for ingestion:

  * `constants.__init__.py`
  * `configuration.mongo_db_connections.py`
  * `data_access/proj1_data.py`
  * `entity/config_entity.py`
  * `entity/artifact_entity.py`
  * `components/data_ingestion.py`
* Set MongoDB connection URL as an environment variable:

  ```bash
  export MONGODB_URL="mongodb+srv://<username>:<password>@..."
  ```
* Run `demo.py` to verify successful data fetching.

---

### 5ï¸âƒ£ Data Validation, Transformation & Model Training

* Define schema details in `config/schema.yaml`.
* Add validation logic in `components.data_validation.py`.
* Perform feature transformations in `components.data_transformation.py`.
* Train ML model in `components.model_trainer.py`.
* Implement custom estimator logic in `entity/estimator.py`.

---

### 6ï¸âƒ£ AWS & Model Deployment Setup

* Create an **IAM user** with `AdministratorAccess`.
* Configure AWS credentials:

  ```bash
  export AWS_ACCESS_KEY_ID="YOUR_KEY"
  export AWS_SECRET_ACCESS_KEY="YOUR_SECRET"
  ```
* Create an **S3 Bucket** for model registry:

  ```
  Bucket Name: my-model-mlopsproj
  ```
* Add AWS configuration in:

  * `constants.__init__.py`
  * `src/configuration/aws_connection.py`
  * `src/aws_storage/s3_estimator.py`
* Build Model Evaluation & Model Pusher components.

---

### 7ï¸âƒ£ CI/CD Pipeline Setup

* Add **App** via `app.py` with routes `/` and `/train`.
* Create `static` and `templates` folders for UI.
* Setup **Docker**:

  ```
  Dockerfile
  .dockerignore
  ```
* Create **GitHub Actions Workflow** under `.github/workflows/aws.yaml`.
* Setup **ECR Repository**:

  ```
  Name: vehicleproj
  Region: us-east-1
  ```
* Create **EC2 Instance** and install Docker:

  ```bash
  curl -fsSL https://get.docker.com -o get-docker.sh
  sudo sh get-docker.sh
  sudo usermod -aG docker ubuntu
  newgrp docker
  ```
* Configure **Self-hosted GitHub Runner** on EC2.
* Add **GitHub Secrets**:

  * `AWS_ACCESS_KEY_ID`
  * `AWS_SECRET_ACCESS_KEY`
  * `AWS_DEFAULT_REGION`
  * `ECR_REPO`
* Commit & Push â€” pipeline triggers automatic deployment.

---

## ğŸ§  Features

âœ… End-to-End ML Pipeline
âœ… Automated Data Ingestion & Validation
âœ… Model Training, Evaluation & Pushing to AWS S3
âœ… Dockerized  Application
âœ… Continuous Integration & Deployment with GitHub Actions
âœ… Real-time Deployment on AWS EC2

---

## ğŸš€ Deployment

Once CI/CD is successful:

1. Open your **EC2 Security Group**.
2. Add inbound rule:

   ```
   Type: Custom TCP
   Port: 5000
   Source: 0.0.0.0/0
   ```
3. Launch the app using:

   ```
   http://<EC2_PUBLIC_IP>:5000
   ```

---

## ğŸ–¥ï¸ App Access

* Visit: `http://<EC2_PUBLIC_IP>:5000`
* Train Model: `http://<EC2_PUBLIC_IP>:5000/train`

---

## ğŸ“¦ Folder Structure

```
ğŸ“‚ Vehicle-MLops-Project
â”‚
â”œâ”€â”€ ğŸ“ src
â”‚   â”œâ”€â”€ components
â”‚   â”œâ”€â”€ configuration
â”‚   â”œâ”€â”€ data_access
â”‚   â”œâ”€â”€ entity
â”‚   â”œâ”€â”€ aws_storage
â”‚   â””â”€â”€ utils
â”‚
â”œâ”€â”€ ğŸ“ notebook
â”‚   â””â”€â”€ mongoDB_demo.ipynb
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ setup.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .github/workflows/aws.yaml
â””â”€â”€ README.md
```

---




